substitutions:
  _PROJECT_ID: 'data-ops-466417'

logsBucket: 'gs://cloudbuild-logs-data-ops-466417'
timeout: 7200s

steps:
  # 1. Terraform Init
  - name: 'hashicorp/terraform:latest'
    entrypoint: 'terraform'
    args: ['init']
    dir: 'terraform'

  # 2. Importar recursos existentes
  - name: 'hashicorp/terraform:latest'
    entrypoint: 'sh'
    dir: 'terraform'
    args:
      - '-c'
      - |
        terraform state list | grep google_storage_bucket.tf_composer_bucket || terraform import google_storage_bucket.tf_composer_bucket tf-composer-bucket
        terraform state list | grep google_storage_bucket.tf_cloud_functions_bucket || terraform import google_storage_bucket.tf_cloud_functions_bucket tf-cloud-functions-bucket
        terraform state list | grep google_storage_bucket.tf_bigquery_scripts_bucket || terraform import google_storage_bucket.tf_bigquery_scripts_bucket tf-bigquery-scripts-bucket
        terraform state list | grep google_compute_network.prod_network || terraform import google_compute_network.prod_network projects/data-ops-466417/global/networks/prod-network
        terraform state list | grep google_compute_subnetwork.prod_subnetwork || terraform import google_compute_subnetwork.prod_subnetwork projects/data-ops-466417/regions/southamerica-east1/subnetworks/prod-subnetwork
  
  # 3. Planejar criação
  - name: 'hashicorp/terraform:latest'
    entrypoint: 'terraform'
    args: ['plan', '-out=tfplan']
    dir: 'terraform'

  # 4. Aplicar criação
  - name: 'hashicorp/terraform:latest'
    entrypoint: 'terraform'
    args: ['apply', '-auto-approve', 'tfplan']
    dir: 'terraform'